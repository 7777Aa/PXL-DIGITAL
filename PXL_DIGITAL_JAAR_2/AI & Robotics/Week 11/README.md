# Week 11: Neural Networks

## 1. Neural Networks
### Goals
The junior-colleague
* can explain how a perceptron works in their own words
* can explain the importance of the activation function in the context of neural networks
* can explain the limitations of perceptrons
* can explain how Neural Networks can handle nonlinear separation
* can describe the concept of gradient descent in the context of neural networks in their own words
* can explain the importance of the learning rate in the context of gradient descent
* can explain how backpropagation works in their own words
* can explain how a Neural Networks is trained in their own words
* can draw a schematic of a neural network and mark the different parts of the network (input, hidden, output layers)


**[Presentation](Week%2011%20-%20Neural%20Networks.pdf)**

On Keras: https://keras.io/getting-started/sequential-model-guide/

#### Videos
- Decision boundaries: https://www.youtube.com/watch?v=bVQUSndDllU
- Neural Networks: 
  - https://www.youtube.com/watch?v=aircAruvnKk
  - https://www.youtube.com/watch?v=IHZwWFHWa-w

### Extra
- A visual proof that neural nets can compute any function: http://neuralnetworksanddeeplearning.com/chap4.html
- The math of Backpropagation: https://www.youtube.com/watch?v=Ilg3gGewQ5U
- Activation functions: 
  - https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/
  - https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6


## Exercises
The PDF file with all the exercises can be found **[here](exercises/Week%2011.pdf)**.
