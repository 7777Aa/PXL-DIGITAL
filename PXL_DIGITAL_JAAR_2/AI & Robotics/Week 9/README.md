# Week 9: Supervised Learning: Data & Optimization

### Goals
The junior-colleague
* can explain the link between data & optimization
* can describe the reasons for understanding your data
* can explain how to prepare and clean a dataset for training a Machine Learning model (categorical variables, dates, missing values)
* can explain one-hot encoding
* can explain the difference between parameters and hyperparameters
* can list and describe 3 ways to tune the hyperparameters of a Machine Learning model
* can list and describe 3 hyperparameters of a Random Forest
* can explain how to acquire the out-of-bag score for a Random Forest and why it's useful
* can explain why feature importance is important in the context of Machine Learning
* can explain the concept of Occam's Razor in the context of Machine Learning
* can describe ways to speed up the training process of a Random Forest


**[Presentation](Week%209%20-%201%20Data%20&%20Optimization.pdf)**

### Extra

#### Fast.AI
The first 4 videos of fast.ai's Machine Learning course more or less cover the material of the past few classes. Be sure to check them out for some extra hands-on information.
- http://course18.fast.ai/lessonsml1/lesson1.html
- http://course18.fast.ai/lessonsml1/lesson2.html
- http://course18.fast.ai/lessonsml1/lesson3.html
- http://course18.fast.ai/lessonsml1/lesson4.html

#### Installation    
- [plotnine](https://plotnine.readthedocs.io/en/stable/installation.html): use the conda installation
- [scikit-misc](https://github.com/has2k1/scikit-misc/blob/master/doc/installation.rst)


